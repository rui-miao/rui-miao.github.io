<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Fast Bandwidth selection for SVM classifier with sample weight - Rui Miao&#39;s Tech Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Rui Miao" /><meta name="description" content="\( \newcommand{\bx}{{\bf x}} \newcommand{\bw}{{\bf w}} \newcommand{\bK}{{\bf K}} \newcommand{\bL}{{\bf L}} \newcommand{\bH}{{\bf H}} \newcommand{\bI}{{\bf I}} \newcommand{\bone}{{\mathbf{1}}} \newcommand{\bzero}{{\mathbf{0}}} \newcommand{\R}{{\mathbb{R}}} \newcommand{\mR}{{\mathcal{R}}} \def\norm#1{\| #1 \|} \def\tr{\mbox{tr}} \def\diag{\mbox{diag}} \def\sign{\mbox{sign}} \def\HSIC{\mbox{HSIC}} \def\ind{\mathbb{I}} \def\E{\mathbb{E}} \def\argmin{\arg\min} \def\argmax{\arg\max} \renewcommand{\t}{\intercal} \) Support Vector Machines (SVMs) are supervised learning methods for classification, regression, etc. We consider classification problem.
Setting We first give a binary classification for example. Given dataset \(\{(\bx_i, y_i)\}_{i=1}^n\) with \(\bx_i\in \R^p\) and class label \(y_i\in \left\{ -1,1 \right\}\), our goal is to find \(w\in \R^r\) and \(b\in \R\) such that the classifier \(\sign(w^{\t} \phi(\bx)&#43;b)\) is correct for most sample points, where \(\phi\) is the feature mapping of some pre-selected kernel \(k(\cdot,\cdot)\)." /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.80.0 with theme even" />


<link rel="canonical" href="https://rui-miao.github.io/post/bandwidthsvm/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.2e81bbed97b8b282c1aeb57488cc71c8d8c8ec559f3931531bd396bf31e0d4dd.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Fast Bandwidth selection for SVM classifier with sample weight" />
<meta property="og:description" content="\( \newcommand{\bx}{{\bf x}} \newcommand{\bw}{{\bf w}} \newcommand{\bK}{{\bf K}} \newcommand{\bL}{{\bf L}} \newcommand{\bH}{{\bf H}} \newcommand{\bI}{{\bf I}} \newcommand{\bone}{{\mathbf{1}}} \newcommand{\bzero}{{\mathbf{0}}} \newcommand{\R}{{\mathbb{R}}} \newcommand{\mR}{{\mathcal{R}}} \def\norm#1{\| #1 \|} \def\tr{\mbox{tr}} \def\diag{\mbox{diag}} \def\sign{\mbox{sign}} \def\HSIC{\mbox{HSIC}} \def\ind{\mathbb{I}} \def\E{\mathbb{E}} \def\argmin{\arg\min} \def\argmax{\arg\max} \renewcommand{\t}{\intercal} \) Support Vector Machines (SVMs) are supervised learning methods for classification, regression, etc. We consider classification problem.
Setting We first give a binary classification for example. Given dataset \(\{(\bx_i, y_i)\}_{i=1}^n\) with \(\bx_i\in \R^p\) and class label \(y_i\in \left\{ -1,1 \right\}\), our goal is to find \(w\in \R^r\) and \(b\in \R\) such that the classifier \(\sign(w^{\t} \phi(\bx)&#43;b)\) is correct for most sample points, where \(\phi\) is the feature mapping of some pre-selected kernel \(k(\cdot,\cdot)\)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://rui-miao.github.io/post/bandwidthsvm/" />
<meta property="article:published_time" content="2021-03-01T23:34:00-05:00" />
<meta property="article:modified_time" content="2021-03-02T23:16:32-05:00" />
<meta itemprop="name" content="Fast Bandwidth selection for SVM classifier with sample weight">
<meta itemprop="description" content="\( \newcommand{\bx}{{\bf x}} \newcommand{\bw}{{\bf w}} \newcommand{\bK}{{\bf K}} \newcommand{\bL}{{\bf L}} \newcommand{\bH}{{\bf H}} \newcommand{\bI}{{\bf I}} \newcommand{\bone}{{\mathbf{1}}} \newcommand{\bzero}{{\mathbf{0}}} \newcommand{\R}{{\mathbb{R}}} \newcommand{\mR}{{\mathcal{R}}} \def\norm#1{\| #1 \|} \def\tr{\mbox{tr}} \def\diag{\mbox{diag}} \def\sign{\mbox{sign}} \def\HSIC{\mbox{HSIC}} \def\ind{\mathbb{I}} \def\E{\mathbb{E}} \def\argmin{\arg\min} \def\argmax{\arg\max} \renewcommand{\t}{\intercal} \) Support Vector Machines (SVMs) are supervised learning methods for classification, regression, etc. We consider classification problem.
Setting We first give a binary classification for example. Given dataset \(\{(\bx_i, y_i)\}_{i=1}^n\) with \(\bx_i\in \R^p\) and class label \(y_i\in \left\{ -1,1 \right\}\), our goal is to find \(w\in \R^r\) and \(b\in \R\) such that the classifier \(\sign(w^{\t} \phi(\bx)&#43;b)\) is correct for most sample points, where \(\phi\) is the feature mapping of some pre-selected kernel \(k(\cdot,\cdot)\).">
<meta itemprop="datePublished" content="2021-03-01T23:34:00-05:00" />
<meta itemprop="dateModified" content="2021-03-02T23:16:32-05:00" />
<meta itemprop="wordCount" content="729">



<meta itemprop="keywords" content="kernel,SVM,Classification,SupervisedLearning," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Fast Bandwidth selection for SVM classifier with sample weight"/>
<meta name="twitter:description" content="\( \newcommand{\bx}{{\bf x}} \newcommand{\bw}{{\bf w}} \newcommand{\bK}{{\bf K}} \newcommand{\bL}{{\bf L}} \newcommand{\bH}{{\bf H}} \newcommand{\bI}{{\bf I}} \newcommand{\bone}{{\mathbf{1}}} \newcommand{\bzero}{{\mathbf{0}}} \newcommand{\R}{{\mathbb{R}}} \newcommand{\mR}{{\mathcal{R}}} \def\norm#1{\| #1 \|} \def\tr{\mbox{tr}} \def\diag{\mbox{diag}} \def\sign{\mbox{sign}} \def\HSIC{\mbox{HSIC}} \def\ind{\mathbb{I}} \def\E{\mathbb{E}} \def\argmin{\arg\min} \def\argmax{\arg\max} \renewcommand{\t}{\intercal} \) Support Vector Machines (SVMs) are supervised learning methods for classification, regression, etc. We consider classification problem.
Setting We first give a binary classification for example. Given dataset \(\{(\bx_i, y_i)\}_{i=1}^n\) with \(\bx_i\in \R^p\) and class label \(y_i\in \left\{ -1,1 \right\}\), our goal is to find \(w\in \R^r\) and \(b\in \R\) such that the classifier \(\sign(w^{\t} \phi(\bx)&#43;b)\) is correct for most sample points, where \(\phi\) is the feature mapping of some pre-selected kernel \(k(\cdot,\cdot)\)."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Rui Miao&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Rui Miao&#39;s Blog</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Fast Bandwidth selection for SVM classifier with sample weight</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-03-01 </span>
        <div class="post-category">
            <a href="/categories/machinelearning/"> MachineLearning </a>
            </div>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#setting">Setting</a></li>
        <li><a href="#method">Method</a>
          <ul>
            <li><a href="#dependency-measure">Dependency Measure</a></li>
            <li><a href="#algorithm">Algorithm</a></li>
          </ul>
        </li>
        <li><a href="#implementation">Implementation</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>\(
\newcommand{\bx}{{\bf x}}
\newcommand{\bw}{{\bf w}}
\newcommand{\bK}{{\bf K}}
\newcommand{\bL}{{\bf L}}
\newcommand{\bH}{{\bf H}}
\newcommand{\bI}{{\bf I}}
\newcommand{\bone}{{\mathbf{1}}}
\newcommand{\bzero}{{\mathbf{0}}}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\mR}{{\mathcal{R}}}
\def\norm#1{\| #1 \|}
\def\tr{\mbox{tr}}
\def\diag{\mbox{diag}}
\def\sign{\mbox{sign}}
\def\HSIC{\mbox{HSIC}}
\def\ind{\mathbb{I}}
\def\E{\mathbb{E}}
\def\argmin{\arg\min}
\def\argmax{\arg\max}
\renewcommand{\t}{\intercal}
\)
Support Vector Machines (SVMs) are supervised learning methods for classification, regression, etc.
We consider <a href="https://scikit-learn.org/stable/modules/svm.html#classification">classification</a> problem.</p>
<h2 id="setting">Setting</h2>
<p>We first give a binary classification for example.
Given dataset \(\{(\bx_i, y_i)\}_{i=1}^n\) with \(\bx_i\in \R^p\) and class label \(y_i\in \left\{ -1,1 \right\}\), our goal is to find \(w\in \R^r\) and \(b\in \R\)
such that the classifier \(\sign(w^{\t} \phi(\bx)+b)\) is correct for most sample points, where \(\phi\) is the feature mapping of some pre-selected kernel \(k(\cdot,\cdot)\).</p>
<p>SVM classifier solves the optimization problem:</p>
<p>\begin{align*}
&amp;\min_{w,b,\zeta} \frac{1}{2} \norm{w}_2^2 + C\sum_{i=1}^n \zeta_i\\\<br>
\text{s.t. } &amp; y_i (w^{\t}\phi(\bx_i)+b) \geq 1-\zeta_i\\\<br>
&amp; \zeta_i\geq 0, i=1,\dots,n.
\end{align*}</p>
<ul>
<li>Ideally, \(y_i(w^{\t}\phi(\bx_i)+b)\geq 1\) for all sample points, i.e. perfect separation.</li>
<li>We allow some samples to be at a distance \(\zeta_i\geq 0\) from the correct margin boundary.</li>
<li>We are trying to maximize the margin by minimizing \(\sum_{i=1}^n \zeta_i\) with controlled \(\ell_2\) energy \(\norm{w}_2^2\).</li>
</ul>
<p>The performance of the kernel based SVM classifier depends on appropriate choice of the kernel \(k(\cdot,\cdot)\) and the penalty parameter \(C\).
One of the most popular used kernel is the Gaussian radial basis function (RBF) kernel:</p>
<p>\begin{equation*}
k(\bx_i,\bx_j) = \exp (-\gamma \norm{\bx_i-\bx_j}_2^2),
\end{equation*}</p>
<p>where \(\gamma\) is the bandwidth parameter of the RBF kernel. We will discuss how to select appropriate \(\gamma\) in next section.</p>
<h2 id="method">Method</h2>
<p>Intuitively, we can try cross-validation to select \(\gamma\) as well as \(C\). But the computational complexity is much higher.
<a href="https://arxiv.org/abs/1804.05214">Damodaran (2018)</a> suggests to select the \(\gamma\) that can maximize the statistical dependency between \(\bx\) (through \(\phi(\bx)\)) and label \(y\). This heuristic approach has very good performance (see their numerical results for details) and can be applied to multi-category classification when \(y_i\in \{c_1,\dots,c_m\}\) of \(m\) categories.</p>
<h3 id="dependency-measure">Dependency Measure</h3>
<p>Hilbert Schmidt Independence Criteria (HSIC) is a independence measure by kernel mean embedding (<a href="https://link.springer.com/chapter/10.1007/11564089%5F7">Gretton et al., 2005</a>).</p>
<ul>
<li>For \(\bx\), let \(k(\cdot,\cdot)\) be the corresponding kernel, \(\phi(\bx)\) the feature mapping and \(\bK\) the Gram matrix.</li>
<li>For \(y\), let \(l(\cdot,\cdot)\) be the corresponding kernel, \(\psi(y)\) the feature mapping and \(\bL\) the Gram matrix.</li>
</ul>
<p>Then the cross-variance operator between two mapping functions is defined by</p>
<p>\begin{equation*}
C_{\bx y} = \E_{\bx y} \left\{ (\phi(\bx)-\E_{\bx}\phi(\bx))\otimes(\psi(y) - \E_{y}\psi(y)) \right\}.
\end{equation*}</p>
<p>The HSIC is defined as the squared Hilber Schmidt norm \(\norm{C_{\bx y}}_{HS}^2\).
The empirical HSIC can be obtained by</p>
<p>\begin{equation}
\label{eq:HSIC}
\HSIC(\{\bx_i,y_i\}_{i=1}^n;k,l) = n^{-2}\tr (\bK\bH\bL\bH),
\end{equation}</p>
<p>where \(\bH = \bI-\frac{1}{n}\bone\bone^{\t}\) is the centering matrix.</p>
<p>Notice that if the SVM will be trained with <a href="https://scikit-learn.org/stable/auto%5Fexamples/svm/plot%5Fweighted%5Fsamples.html#sphx-glr-auto-examples-svm-plot-weighted-samples-py">sample weights</a> \(\bw = [w_1,\dots,w_n]^{\t}\), \(\sum_iw_i=1, w_i&gt;0\), one should use \(\bH = \diag(\bw) - \bw\bw^{\t}\), and omit the \(n^{-2}\) in \eqref{eq:HSIC}.</p>
<h3 id="algorithm">Algorithm</h3>
<p>The basic procedure is: for a fixed target kernel \(l(\cdot,\cdot)\) based on labels of \(y_i\)&rsquo;s, select a bandwidth parameter \(\gamma\) of \(k(\cdot,\cdot)\) that can maximize HSIC in \eqref{eq:HSIC}.</p>
<p>The target kernel is given by <a href="https://jmlr.csail.mit.edu/papers/volume13/song12a/song12a.pdf">Song et al. (2012) Section 5.2.2</a>. Explicitly,</p>
<p>\begin{equation}
\label{eq:tarKernel}
l(y_i,y_j) = \frac{1}{\# c_{y_i}} \ind(y_i=y_j),
\end{equation}</p>
<p>where \(\#c_{y_i}\) is the total number of the category of \(y_i\) in the dataset.</p>
<ol>
<li>
<p>Input: \(\{\bx_i,y_i\}_{i=1}^n\) the training samples and corresponding labels</p>
</li>
<li>
<p>\(\gamma=\left[p^{th}\mbox{quantile}\{\norm{\bx_i-\bx_j}_2^2\}_{1\leq i&lt;j\leq n}\right]^{-1}\), \(p=10\%,20\%,\dots,90\%\).</p>
</li>
<li>
<p><strong>For</strong> each \(\gamma\) <strong>do</strong>:</p>
<p>Compute \(\HSIC_{\gamma}\) by \eqref{eq:HSIC}</p>
</li>
<li>
<p>\(\gamma^{\star}= \argmax_{\gamma} \HSIC_{\gamma}\)</p>
</li>
<li>
<p>Cross validate \(C\) for SVM classifier with RBF kernel with bandwidth parameter \(\gamma^{\star}\).</p>
</li>
</ol>
<h2 id="implementation">Implementation</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">import numpy as np
import sklearn

def FastOptBW(X, y, sample_weight=None, n_gammas=10):
        &#34;&#34;&#34;
        Fast Optimal Bandwidth Selection for RBF Kernel using HSIC (Damodaran 2018, IEEE)
        Input:
            X: covariates of SVM
            y: response of SVM: {-1,1}
            sample_weight: for weight w_i on sample (X_i,y_i), a posiitive np vector with sum=1
            n_gammas: number of gammas to try
        Output:
            Optimal gamma for the RBF kernel in terms of classification
        &#34;&#34;&#34;
        params = {&#34;squared&#34;: True}
        K_X_euclidean = sklearn.metrics.pairwise_distances(X = X, n_jobs=-1, metric=&#39;euclidean&#39;, **params)
        gammas = 1./np.quantile(K_X_euclidean[np.tril_indices(X.shape[0],-1)], np.array(range(1, n_gammas))/n_gammas)

        reci_pos = 2./(y.shape[0] + np.sum(y))
        reci_neg = 2./(y.shape[0] - np.sum(y))
        K_y = np.zeros((y.shape[0],y.shape[0]), dtype=float)
        K_y[y&gt;0,y&gt;0]=reci_pos
        K_y[y&lt;0,y&lt;0]=reci_neg
        if sample_weight is None:
            H = np.eye(X.shape[0]) - np.ones((X.shape[0], X.shape[0]), dtype=float)/X.shape[0] # centering matrix
        else:
            if np.any(sample_weight&lt;0):
                raise ValueError(&#39;Negative weight detected!&#39;)
            sample_weight = sample_weight/np.sum(sample_weight) #standardization
            H = np.diag(sample_weight) - sample_weight @ sample_weight.T
        HK_yH = H@K_y@H

        HSICs = []
        K_X = np.zeros_like(K_X_euclidean)
        for gamma in gammas:
            K_X = np.exp(-gamma*K_X_euclidean, K_X)
            HSICs.append(np.trace(K_X@HK_yH))

        return gammas[np.argmax(np.array(HSICs))]</code></pre></td></tr></table>
</div>
</div>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Rui Miao</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2021-03-02
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/kernel/">kernel</a>
          <a href="/tags/svm/">SVM</a>
          <a href="/tags/classification/">Classification</a>
          <a href="/tags/supervisedlearning/">SupervisedLearning</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/vscodesshproxyjump/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Visual Studio Code Remote-SSH with ProxyJump</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/test/">
            <span class="next-text nav-default">Test</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  
    <script src="https://utteranc.es/client.js"
            repo="rui-miao/BlogComments"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://github.com/utterance">comments powered by utterances.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:ruimiao@gwu.edu" class="iconfont icon-email" title="email"></a>
      <a href="https://www.linkedin.com/in/ruimiao/" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="https://github.com/rui-miao" class="iconfont icon-github" title="github"></a>
  <a href="https://rui-miao.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>Rui Miao</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        tags: 'ams',
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>








</body>
</html>
